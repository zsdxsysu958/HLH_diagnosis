import streamlit as st
import joblib
import numpy as np
import pandas as pd
import os
import requests
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler

# ğŸ”— GitHub RAW é“¾æ¥ï¼ˆæ›¿æ¢ä¸ºä½ çš„ä»“åº“ï¼‰
MODEL_URL = "https://raw.githubusercontent.com/zsdxsysu958/HLH_diagnosis/main/random_forest_model.pkl"
SCALER_URL = "https://raw.githubusercontent.com/zsdxsysu958/HLH_diagnosis/main/scaler.pkl"

# ğŸ¯ **åŠ è½½æ¨¡å‹**
@st.cache_resource
def load_model():
    model_path = "/mnt/data/random_forest_model.pkl"
    scaler_path = "/mnt/data/scaler.pkl"

    # å¦‚æœæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™ä» GitHub ä¸‹è½½
    if not os.path.exists(model_path):
        st.info("ğŸ”½ æ­£åœ¨ä» GitHub ä¸‹è½½æ¨¡å‹æ–‡ä»¶...")
        response = requests.get(MODEL_URL)
        with open(model_path, "wb") as f:
            f.write(response.content)

    if not os.path.exists(scaler_path):
        st.info("ğŸ”½ æ­£åœ¨ä» GitHub ä¸‹è½½æ ‡å‡†åŒ–å·¥å…·...")
        response = requests.get(SCALER_URL)
        with open(scaler_path, "wb") as f:
            f.write(response.content)

    # åŠ è½½æ¨¡å‹
    model = joblib.load(model_path)
    scaler = joblib.load(scaler_path)
    return model, scaler

# åŠ è½½æ¨¡å‹
model, scaler = load_model()
st.success("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼Œå¯ä»¥è¿›è¡Œé¢„æµ‹ï¼")

# ğŸ¯ **é¡µé¢æ ‡é¢˜**
st.title("ğŸ©º HLH é¢„æµ‹æ¨¡å‹")

st.sidebar.header("ğŸ“Š è¯·è¾“å…¥æ‚£è€…æ•°æ®")
Ferritin = st.sidebar.number_input("Ferritin (ng/mL)", min_value=0)
LDH = st.sidebar.number_input("LDH (IU/L)", min_value=0)
TRIG = st.sidebar.number_input("TRIG (mg/dL)", min_value=0)
TBA = st.sidebar.number_input("TBA (umol/L)", min_value=0)
eGFR = st.sidebar.number_input("eGFR-EPI (mL/min/1.73mÂ²)", min_value=0)

# ğŸ¯ **è½¬æ¢æˆæ¨¡å‹è¾“å…¥æ ¼å¼**
input_data = np.array([[Ferritin, LDH, TRIG, TBA, eGFR]])
input_data_scaled = scaler.transform(input_data)  # ä½¿ç”¨è®­ç»ƒæ—¶çš„scalerè¿›è¡Œæ ‡å‡†åŒ–

# ğŸ¯ **é¢„æµ‹ HLH é£é™©**
if st.button("ğŸ” é¢„æµ‹ HLH é£é™©"):
    hlh_probability = model.predict_proba(input_data_scaled)[:, 1]  # è·å– HLH é¢„æµ‹æ¦‚ç‡

    # è®¾å®šé£é™©ç­‰çº§
    if hlh_probability[0] > 0.8:
        risk_level = "âš ï¸ é«˜é£é™©"
    elif hlh_probability[0] > 0.5:
        risk_level = "âš ï¸ ä¸­ç­‰é£é™©"
    else:
        risk_level = "âœ… ä½é£é™©"

    # ğŸ¯ **æ˜¾ç¤ºé¢„æµ‹ç»“æœ**
    st.write(f"ğŸ’¡ **HLH é¢„æµ‹æ¦‚ç‡: {hlh_probability[0]:.2f}**")
    st.write(f"ğŸ©º **é£é™©ç­‰çº§: {risk_level}**")

    # ğŸ¯ **ä¸‹è½½é¢„æµ‹ç»“æœ**
    result_df = pd.DataFrame({
        "Ferritin": [Ferritin],
        "LDH": [LDH],
        "TRIG": [TRIG],
        "TBA": [TBA],
        "eGFR-EPI": [eGFR],
        "HLH é¢„æµ‹æ¦‚ç‡": [hlh_probability[0]],
        "é£é™©ç­‰çº§": [risk_level]
    })

    st.download_button(
        label="ğŸ“¥ ä¸‹è½½é¢„æµ‹ç»“æœ",
        data=result_df.to_csv(index=False, encoding="utf-8"),
        file_name="HLH_prediction_results.csv",
        mime="text/csv"
    )
